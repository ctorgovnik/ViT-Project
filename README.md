# ViT-Project

## Introduction

## Chosen Result

## GitHub Contents

## Re-implementation Details

## Reproduction Steps

## Results/Insights

## Conclusion

## References

## Acknowledgements
[1] Ashish Vaswani et al. “Attention is All You Need”. In: Advances in Neural Information Processing Systems.
Vol. 30. Curran Associates, Inc., 2017. <br><br>
[2] Alexey Dosovitskiy et al. “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”.
In: International Conference on Learning Representations (ICLR). arXiv:2010.11929. 2021.<br><br>
[3] Alex Krizhevsky. Learning multiple layers of features from tiny images. Tech. rep. University of Toronto,
2009. url: https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf.<br><br>
[4] Facebook AI. deit-tiny-patch16-224 on HuggingFace. https://huggingface.co/facebook/deit-tiny-
patch16-224. https://huggingface.co/facebook/deit-tiny-patch16-224. 2024.<br><br>
[5] PyTorch Team. Torchvision Models. https : / / pytorch . org / vision / main / models . html. https : / /
pytorch.org/vision/main/models.html. 2024
